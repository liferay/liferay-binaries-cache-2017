{
  "manifest": {
    "name": "remark-parse",
    "version": "6.0.3",
    "description": "Markdown parser for remark",
    "license": "MIT",
    "keywords": [
      "markdown",
      "abstract",
      "syntax",
      "tree",
      "ast",
      "parse"
    ],
    "homepage": "https://remark.js.org/",
    "repository": {
      "type": "git",
      "url": "https://github.com/remarkjs/remark/tree/master/packages/remark-parse"
    },
    "bugs": {
      "url": "https://github.com/remarkjs/remark/issues"
    },
    "author": {
      "name": "Titus Wormer",
      "email": "tituswormer@gmail.com",
      "url": "https://wooorm.com"
    },
    "contributors": [
      {
        "name": "Titus Wormer",
        "email": "tituswormer@gmail.com",
        "url": "https://wooorm.com"
      },
      {
        "name": "Eugene Sharygin",
        "email": "eush77@gmail.com"
      },
      {
        "name": "Junyoung Choi",
        "email": "fluke8259@gmail.com"
      },
      {
        "name": "Elijah Hamovitz",
        "email": "elijahhamovitz@gmail.com"
      },
      {
        "name": "Ika",
        "email": "ikatyang@gmail.com"
      }
    ],
    "files": [
      "index.js",
      "lib"
    ],
    "dependencies": {
      "collapse-white-space": "^1.0.2",
      "is-alphabetical": "^1.0.0",
      "is-decimal": "^1.0.0",
      "is-whitespace-character": "^1.0.0",
      "is-word-character": "^1.0.0",
      "markdown-escapes": "^1.0.0",
      "parse-entities": "^1.1.0",
      "repeat-string": "^1.5.4",
      "state-toggle": "^1.0.0",
      "trim": "0.0.1",
      "trim-trailing-lines": "^1.0.0",
      "unherit": "^1.0.4",
      "unist-util-remove-position": "^1.0.0",
      "vfile-location": "^2.0.0",
      "xtend": "^4.0.1"
    },
    "devDependencies": {
      "tape": "^4.9.1",
      "unified": "^7.0.0",
      "vfile": "^3.0.0"
    },
    "scripts": {
      "test": "tape test.js"
    },
    "xo": false,
    "_registry": "npm",
    "_loc": "P:\\project\\lfm\\liferay-binaries-cache-2017\\.yarn\\v4\\npm-remark-parse-6.0.3-c99131052809da482108413f87b0ee7f52180a3a\\node_modules\\remark-parse\\package.json",
    "readmeFilename": "readme.md",
    "readme": "# remark-parse [![Travis][build-badge]][build-status] [![Coverage][coverage-badge]][coverage-status] [![Downloads][dl-badge]][dl] [![Size][size-badge]][size] [![Chat][chat-badge]][chat]\n\n[Parser][] for [**unified**][unified].\nParses markdown to [**mdast**][mdast] syntax trees.\nUsed in the [**remark** processor][processor] but can be used on its own as\nwell.\nCan be [extended][extend] to change how markdown is parsed.\n\n* * *\n\n**Announcing the unified collective!  üéâ\n[Read more about it on Medium ¬ª][announcement]**\n\n## Sponsors\n\n<!--lint ignore no-html maximum-line-length-->\n\n<table>\n  <tr valign=\"top\">\n    <td width=\"20%\" align=\"center\">\n      <a href=\"https://zeit.co\"><img src=\"https://avatars1.githubusercontent.com/u/14985020?s=400&v=4\"></a>\n      <br><br>ü•á\n      <a href=\"https://zeit.co\">ZEIT</a>\n    </td>\n    <td width=\"20%\" align=\"center\">\n      <a href=\"https://www.gatsbyjs.org\"><img src=\"https://avatars1.githubusercontent.com/u/12551863?s=400&v=4\"></a>\n      <br><br>ü•á\n      <a href=\"https://www.gatsbyjs.org\">Gatsby</a></td>\n    <td width=\"20%\" align=\"center\">\n      <a href=\"https://compositor.io\"><img src=\"https://avatars1.githubusercontent.com/u/19245838?s=400&v=4\"></a>\n      <br><br>ü•â\n      <a href=\"https://compositor.io\">Compositor</a>\n    </td>\n    <td width=\"20%\" align=\"center\">\n      <a href=\"https://www.holloway.com\"><img src=\"https://avatars1.githubusercontent.com/u/35904294?s=400&v=4\"></a>\n      <br><br>\n      <a href=\"https://www.holloway.com\">Holloway</a>\n    </td>\n    <td width=\"20%\" align=\"center\">\n      <br><br><br><br>\n      <a href=\"https://opencollective.com/unified\"><strong>You?</strong>\n    </td>\n  </tr>\n</table>\n\n## Installation\n\n[npm][]:\n\n```sh\nnpm install remark-parse\n```\n\n## Usage\n\n```js\nvar unified = require('unified')\nvar createStream = require('unified-stream')\nvar markdown = require('remark-parse')\nvar html = require('remark-html')\n\nvar processor = unified()\n  .use(markdown, {commonmark: true})\n  .use(html)\n\nprocess.stdin.pipe(createStream(processor)).pipe(process.stdout)\n```\n\n## Table of Contents\n\n*   [API](#api)\n    *   [processor.use(parse\\[, options\\])](#processoruseparse-options)\n    *   [parse.Parser](#parseparser)\n*   [Extending the Parser](#extending-the-parser)\n    *   [Parser#blockTokenizers](#parserblocktokenizers)\n    *   [Parser#blockMethods](#parserblockmethods)\n    *   [Parser#inlineTokenizers](#parserinlinetokenizers)\n    *   [Parser#inlineMethods](#parserinlinemethods)\n    *   [function tokenizer(eat, value, silent)](#function-tokenizereat-value-silent)\n    *   [tokenizer.locator(value, fromIndex)](#tokenizerlocatorvalue-fromindex)\n    *   [eat(subvalue)](#eatsubvalue)\n    *   [add(node\\[, parent\\])](#addnode-parent)\n    *   [add.test()](#addtest)\n    *   [add.reset(node\\[, parent\\])](#addresetnode-parent)\n    *   [Turning off a tokenizer](#turning-off-a-tokenizer)\n*   [License](#license)\n\n## API\n\n### `processor.use(parse[, options])`\n\nConfigure the `processor` to read markdown as input and process\n[**mdast**][mdast] syntax trees.\n\n##### `options`\n\nOptions are passed directly, or passed later through [`processor.data()`][data].\n\n##### `options.gfm`\n\n```md\nhello ~~hi~~ world\n```\n\nGFM mode (`boolean`, default: `true`) turns on:\n\n*   [Fenced code blocks](https://help.github.com/articles/github-flavored-markdown/#fenced-code-blocks)\n*   [Autolinking of URLs](https://help.github.com/articles/github-flavored-markdown/#url-autolinking)\n*   [Deletions (strikethrough)](https://help.github.com/articles/github-flavored-markdown/#strikethrough)\n*   [Task lists](https://help.github.com/articles/writing-on-github/#task-lists)\n*   [Tables](https://help.github.com/articles/github-flavored-markdown/#tables)\n\n##### `options.commonmark`\n\n```md\nThis is a paragraph\n    and this is also part of the preceding paragraph.\n```\n\nCommonMark mode (`boolean`, default: `false`) allows:\n\n*   Empty lines to split blockquotes\n*   Parentheses (`(` and `)`) around for link and image titles\n*   Any escaped [ASCII-punctuation][escapes] character\n*   Closing parenthesis (`)`) as an ordered list marker\n*   URL definitions (and footnotes, when enabled) in blockquotes\n\nCommonMark mode disallows:\n\n*   Code directly following a paragraph\n*   ATX-headings (`# Hash headings`) without spacing after opening hashes\n    or and before closing hashes\n*   Setext headings (`Underline headings\\n---`) when following a paragraph\n*   Newlines in link and image titles\n*   White space in link and image URLs in auto-links (links in brackets,\n    `<` and `>`)\n*   Lazy blockquote continuation, lines not preceded by a closing angle\n    bracket (`>`), for lists, code, and thematicBreak\n\n##### `options.footnotes`\n\n```md\nSomething something[^or something?].\n\nAnd something else[^1].\n\n[^1]: This reference footnote contains a paragraph...\n\n    * ...and a list\n```\n\nFootnotes mode (`boolean`, default: `false`) enables reference footnotes and\ninline footnotes.  Both are wrapped in square brackets and preceded by a caret\n(`^`), and can be referenced from inside other footnotes.\n\n##### `options.blocks`\n\n```md\n<block>foo\n</block>\n```\n\nBlocks (`Array.<string>`, default: list of [block HTML elements][blocks])\nexposes let‚Äôs users define block-level HTML elements.\n\n##### `options.pedantic`\n\n```md\nCheck out some_file_name.txt\n```\n\nPedantic mode (`boolean`, default: `false`) turns on:\n\n*   Emphasis (`_alpha_`) and importance (`__bravo__`) with underscores\n    in words\n*   Unordered lists with different markers (`*`, `-`, `+`)\n*   If `commonmark` is also turned on, ordered lists with different\n    markers (`.`, `)`)\n*   And pedantic mode removes less spaces in list-items (at most four,\n    instead of the whole indent)\n\n### `parse.Parser`\n\nAccess to the [parser][], if you need it.\n\n## Extending the Parser\n\nMost often, using transformers to manipulate a syntax tree produces\nthe desired output.  Sometimes, mainly when introducing new syntactic\nentities with a certain level of precedence, interfacing with the parser\nis necessary.\n\nIf the `remark-parse` plugin is used, it adds a [`Parser`][parser] constructor\nto the `processor`.  Other plugins can add tokenizers to the parser‚Äôs prototype\nto change how markdown is parsed.\n\nThe below plugin adds a [tokenizer][] for at-mentions.\n\n```js\nmodule.exports = mentions\n\nfunction mentions() {\n  var Parser = this.Parser\n  var tokenizers = Parser.prototype.inlineTokenizers\n  var methods = Parser.prototype.inlineMethods\n\n  // Add an inline tokenizer (defined in the following example).\n  tokenizers.mention = tokenizeMention\n\n  // Run it just before `text`.\n  methods.splice(methods.indexOf('text'), 0, 'mention')\n}\n```\n\n### `Parser#blockTokenizers`\n\nAn object mapping tokenizer names to [tokenizer][]s.  These\ntokenizers (for example: `fencedCode`, `table`, and `paragraph`) eat\nfrom the start of a value to a line ending.\n\nSee `#blockMethods` below for a list of methods that are included by\ndefault.\n\n### `Parser#blockMethods`\n\nArray of `blockTokenizers` names (`string`) specifying the order in\nwhich they run.\n\n<!--methods-block start-->\n\n*   `newline`\n*   `indentedCode`\n*   `fencedCode`\n*   `blockquote`\n*   `atxHeading`\n*   `thematicBreak`\n*   `list`\n*   `setextHeading`\n*   `html`\n*   `footnote`\n*   `definition`\n*   `table`\n*   `paragraph`\n\n<!--methods-block end-->\n\n### `Parser#inlineTokenizers`\n\nAn object mapping tokenizer names to [tokenizer][]s.  These tokenizers\n(for example: `url`, `reference`, and `emphasis`) eat from the start\nof a value.  To increase performance, they depend on [locator][]s.\n\nSee `#inlineMethods` below for a list of methods that are included by\ndefault.\n\n### `Parser#inlineMethods`\n\nArray of `inlineTokenizers` names (`string`) specifying the order in\nwhich they run.\n\n<!--methods-inline start-->\n\n*   `escape`\n*   `autoLink`\n*   `url`\n*   `html`\n*   `link`\n*   `reference`\n*   `strong`\n*   `emphasis`\n*   `deletion`\n*   `code`\n*   `break`\n*   `text`\n\n<!--methods-inline end-->\n\n### `function tokenizer(eat, value, silent)`\n\n```js\ntokenizeMention.notInLink = true\ntokenizeMention.locator = locateMention\n\nfunction tokenizeMention(eat, value, silent) {\n  var match = /^@(\\w+)/.exec(value)\n\n  if (match) {\n    if (silent) {\n      return true\n    }\n\n    return eat(match[0])({\n      type: 'link',\n      url: 'https://social-network/' + match[1],\n      children: [{type: 'text', value: match[0]}]\n    })\n  }\n}\n```\n\nThe parser knows two types of tokenizers: block level and inline level.\nBlock level tokenizers are the same as inline level tokenizers, with\nthe exception that the latter must have a [locator][].\n\nTokenizers _test_ whether a document starts with a certain syntactic\nentity.  In _silent_ mode, they return whether that test passes.\nIn _normal_ mode, they consume that token, a process which is called\n‚Äúeating‚Äù.  Locators enable tokenizers to function faster by providing\ninformation on where the next entity may occur.\n\n###### Signatures\n\n*   `Node? = tokenizer(eat, value)`\n*   `boolean? = tokenizer(eat, value, silent)`\n\n###### Parameters\n\n*   `eat` ([`Function`][eat]) ‚Äî Eat, when applicable, an entity\n*   `value` (`string`) ‚Äî Value which may start an entity\n*   `silent` (`boolean`, optional) ‚Äî Whether to detect or consume\n\n###### Properties\n\n*   `locator` ([`Function`][locator])\n    ‚Äî Required for inline tokenizers\n*   `onlyAtStart` (`boolean`)\n    ‚Äî Whether nodes can only be found at the beginning of the document\n*   `notInBlock` (`boolean`)\n    ‚Äî Whether nodes cannot be in blockquotes, lists, or footnote\n    definitions\n*   `notInList` (`boolean`)\n    ‚Äî Whether nodes cannot be in lists\n*   `notInLink` (`boolean`)\n    ‚Äî Whether nodes cannot be in links\n\n###### Returns\n\n*   In _silent_ mode, whether a node can be found at the start of `value`\n*   In _normal_ mode, a node if it can be found at the start of `value`\n\n### `tokenizer.locator(value, fromIndex)`\n\n```js\nfunction locateMention(value, fromIndex) {\n  return value.indexOf('@', fromIndex)\n}\n```\n\nLocators are required for inline tokenization to keep the process\nperformant.  Locators enable inline tokenizers to function faster by\nproviding information on the where the next entity occurs.  Locators\nmay be wrong, it‚Äôs OK if there actually isn‚Äôt a node to be found at\nthe index they return, but they must skip any nodes.\n\n###### Parameters\n\n*   `value` (`string`) ‚Äî Value which may contain an entity\n*   `fromIndex` (`number`) ‚Äî Position to start searching at\n\n###### Returns\n\nIndex at which an entity may start, and `-1` otherwise.\n\n### `eat(subvalue)`\n\n```js\nvar add = eat('foo')\n```\n\nEat `subvalue`, which is a string at the start of the\n[tokenize][tokenizer]d `value` (it‚Äôs tracked to ensure the correct\nvalue is eaten).\n\n###### Parameters\n\n*   `subvalue` (`string`) - Value to eat.\n\n###### Returns\n\n[`add`][add].\n\n### `add(node[, parent])`\n\n```js\nvar add = eat('foo')\n\nadd({type: 'text', value: 'foo'})\n```\n\nAdd [positional information][location] to `node` and add it to `parent`.\n\n###### Parameters\n\n*   `node` ([`Node`][node]) - Node to patch position on and insert\n*   `parent` ([`Node`][node], optional) - Place to add `node` to in\n    the syntax tree.  Defaults to the currently processed node\n\n###### Returns\n\nThe given `node`.\n\n### `add.test()`\n\nGet the [positional information][location] which would be patched on\n`node` by `add`.\n\n###### Returns\n\n[`Location`][location].\n\n### `add.reset(node[, parent])`\n\n`add`, but resets the internal location.  Useful for example in\nlists, where the same content is first eaten for a list, and later\nfor list items\n\n###### Parameters\n\n*   `node` ([`Node`][node]) - Node to patch position on and insert\n*   `parent` ([`Node`][node], optional) - Place to add `node` to in\n    the syntax tree.  Defaults to the currently processed node\n\n###### Returns\n\nThe given `node`.\n\n### Turning off a tokenizer\n\nIn rare situations, you may want to turn off a tokenizer to avoid parsing\nthat syntactic feature.  This can be done by replacing the tokenizer from\nyour Parser‚Äôs `blockTokenizers` (or `blockMethods`) or `inlineTokenizers`\n(or `inlineMethods`).\n\nThe following example turns off indented code blocks:\n\n```js\nremarkParse.Parser.prototype.blockTokenizers.indentedCode = indentedCode\n\nfunction indentedCode() {\n  return true\n}\n```\n\nPreferably, just use [this plugin](https://github.com/zestedesavoir/zmarkdown/tree/master/packages/remark-disable-tokenizers).\n\n## License\n\n[MIT][license] ¬© [Titus Wormer][author]\n\n<!-- Definitions -->\n\n[build-badge]: https://img.shields.io/travis/remarkjs/remark/master.svg\n\n[build-status]: https://travis-ci.org/remarkjs/remark\n\n[coverage-badge]: https://img.shields.io/codecov/c/github/remarkjs/remark.svg\n\n[coverage-status]: https://codecov.io/github/remarkjs/remark\n\n[dl-badge]: https://img.shields.io/npm/dm/remark-parse.svg\n\n[dl]: https://www.npmjs.com/package/remark-parse\n\n[size-badge]: https://img.shields.io/bundlephobia/minzip/remark-parse.svg\n\n[size]: https://bundlephobia.com/result?p=remark-parse\n\n[chat-badge]: https://img.shields.io/badge/join%20the%20community-on%20spectrum-7b16ff.svg\n\n[chat]: https://spectrum.chat/unified/remark\n\n[license]: https://github.com/remarkjs/remark/blob/master/license\n\n[author]: https://wooorm.com\n\n[npm]: https://docs.npmjs.com/cli/install\n\n[unified]: https://github.com/unifiedjs/unified\n\n[data]: https://github.com/unifiedjs/unified#processordatakey-value\n\n[processor]: https://github.com/remarkjs/remark/blob/master/packages/remark\n\n[mdast]: https://github.com/syntax-tree/mdast\n\n[escapes]: https://spec.commonmark.org/0.28/#backslash-escapes\n\n[node]: https://github.com/syntax-tree/unist#node\n\n[location]: https://github.com/syntax-tree/unist#location\n\n[parser]: https://github.com/unifiedjs/unified#processorparser\n\n[extend]: #extending-the-parser\n\n[tokenizer]: #function-tokenizereat-value-silent\n\n[locator]: #tokenizerlocatorvalue-fromindex\n\n[eat]: #eatsubvalue\n\n[add]: #addnode-parent\n\n[blocks]: https://github.com/remarkjs/remark/blob/master/packages/remark-parse/lib/block-elements.js\n\n[announcement]: https://medium.com/unifiedjs/collectively-evolving-through-crowdsourcing-22c359ea95cc\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/remark-parse/-/remark-parse-6.0.3.tgz#c99131052809da482108413f87b0ee7f52180a3a",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/remark-parse/-/remark-parse-6.0.3.tgz",
    "hash": "c99131052809da482108413f87b0ee7f52180a3a",
    "integrity": "sha512-QbDXWN4HfKTUC0hHa4teU463KclLAnwpn/FBn87j9cKYJWWawbiLgMfP2Q4XwhxxuuuOxHlw+pSN0OKuJwyVvg==",
    "registry": "npm",
    "packageName": "remark-parse"
  },
  "registry": "npm",
  "hash": "c99131052809da482108413f87b0ee7f52180a3a"
}